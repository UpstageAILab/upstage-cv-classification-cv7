{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification baseline code**\n","> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n","> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n","\n","## Contents\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["## 1. Prepare Environments\n","\n","* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n","* 필요한 라이브러리를 설치합니다."]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21945,"status":"ok","timestamp":1700314517484,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"pUjnEto4gIZm","outputId":"0999f10c-e1ff-428c-995b-481eec8a0b58"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /gdrive\n","Mounted at /content/drive\n"]}],"source":["# # 구글 드라이브 마운트, Colab을 이용하지 않는다면 패스해도 됩니다.\n","# from google.colab import drive\n","# drive.mount('/gdrive', force_remount=True)\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":7640,"status":"ok","timestamp":1700314537985,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"5lFQ-gpjnN_m"},"outputs":[],"source":["# # 구글 드라이브에 업로드된 대회 데이터를 압축 해제하고 로컬에 저장합니다.\n","# !tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.12)\n","Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.0)\n","Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.0)\n","Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\n","Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.4)\n","Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.9.0)\n","Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.7.1)\n","Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.11.1)\n","Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2023.9.2)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.65.0)\n","Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (23.1)\n","Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n","Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mRequirement already satisfied: augraphy in /opt/conda/lib/python3.10/site-packages (8.2.6)\n","Requirement already satisfied: matplotlib>=3.4.3 in /opt/conda/lib/python3.10/site-packages (from augraphy) (3.8.2)\n","Requirement already satisfied: numba>=0.57.0 in /opt/conda/lib/python3.10/site-packages (from augraphy) (0.59.0)\n","Requirement already satisfied: numpy>=1.20.1 in /opt/conda/lib/python3.10/site-packages (from augraphy) (1.26.0)\n","Requirement already satisfied: opencv-python>=4.5.1.48 in /opt/conda/lib/python3.10/site-packages (from augraphy) (4.9.0.80)\n","Requirement already satisfied: Pillow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from augraphy) (9.4.0)\n","Requirement already satisfied: requests>=2.25.1 in /opt/conda/lib/python3.10/site-packages (from augraphy) (2.31.0)\n","Requirement already satisfied: scikit-image>=0.18.1 in /opt/conda/lib/python3.10/site-packages (from augraphy) (0.22.0)\n","Requirement already satisfied: scikit-learn>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from augraphy) (1.3.2)\n","Requirement already satisfied: scipy>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from augraphy) (1.11.4)\n","Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (4.48.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (3.1.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (2.8.2)\n","Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.57.0->augraphy) (0.42.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (2.0.4)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (1.26.16)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (2023.7.22)\n","Requirement already satisfied: networkx>=2.8 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (3.1)\n","Requirement already satisfied: imageio>=2.27 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (2.33.1)\n","Requirement already satisfied: tifffile>=2022.8.12 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (2023.12.9)\n","Requirement already satisfied: lazy_loader>=0.3 in /opt/conda/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (0.3)\n","Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->augraphy) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.23.2->augraphy) (3.2.0)\n","Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.3->augraphy) (1.16.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install timm\n","!pip install augraphy"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: opencv-python in /opt/conda/lib/python3.10/site-packages (4.9.0.80)\n","Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python) (1.26.0)\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m"]}],"source":["!pip install opencv-python"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8489,"status":"ok","timestamp":1700314558888,"user":{"displayName":"Ynot(송원호)","userId":"16271863862696372773"},"user_tz":-540},"id":"NC8V-D393wY4","outputId":"e9927325-26c4-4b89-9c51-c1d6541388d6"},"outputs":[],"source":["import os\n","import pandas as pd\n","import numpy as np\n","import cv2\n","from PIL import Image\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","from augraphy import *\n","import timm\n","import torch\n","import torch.nn as nn\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import NAdam\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions\n","* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n","* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["train_transform = A.Compose([\n","    A.Resize(height=512, width=512),\n","    A.HorizontalFlip(p=0.35),\n","    A.VerticalFlip(p=0.35),\n","    A.OneOf([A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=(15, 25)),A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=(-15, -25))], p=0.3),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])\n","test_transform = A.Compose([\n","    A.Resize(height=512, width=512),\n","    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    ToTensorV2(),\n","])\n","train_augraphy = AugraphyPipeline([\n","BadPhotoCopy(),DirtyDrum(),NoiseTexturize(),Folding(), ShadowCast(shadow_opacity_range=(0,0.35)), LightingGradient(), LowLightNoise(p = 0.5)])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0d699c02c33a4e159659d8e66660eb71","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/1.90G [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None, augraphy=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","        self.augraphy = augraphy\n","    def __len__(self):\n","        return len(self.df)\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if img.shape[1] > img.shape[0]:\n","            img = cv2.rotate(img, cv2.ROTATE_90_CLOCKWISE)\n","        if self.augraphy:\n","            img = self.augraphy(img)\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target\n","\n","model = timm.create_model('maxvit_xlarge_tf_512', pretrained=True, num_classes=17).to(device)\n","optimizer = NAdam(model.parameters(), lr=5e-5)\n","loss_fn = nn.CrossEntropyLoss()\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.7155280309067065\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.8926140299387384\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:03<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9219651505349328\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9425009027839776\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9590528283245899\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9672461568407729\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9591101856721209\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9727300550608137\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9748738172987712\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9666927593767591\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.98328497961358\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9765614035496112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9708922179808447\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9819289530954926\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9818298101510161\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9837944766986306\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9838557512919287\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9809631294074218\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9860144674620372\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9879333328703048\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9817004733132151\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9824949075701466\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9788697693298741\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9885356315985119\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9870565987030112\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9857189559012253\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9840277006324918\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9864989375891287\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.89it/s]\n"]},{"name":"stdout","output_type":"stream","text":["0.9859858036290584\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 1570/1570 [09:02<00:00,  2.90it/s]"]},{"name":"stdout","output_type":"stream","text":["0.9914194631843429\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for _ in range(30):\n","    model.train()\n","    train_dataset = ImageDataset(\"/data/ephemeral/home/data/train.csv\", \"/data/ephemeral/home/data/train\", transform=train_transform, augraphy= train_augraphy)\n","    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True, drop_last=True)\n","    preds_list, targets_list = [], []\n","    for image, targets in tqdm(train_loader):\n","        image, targets = image.to(device), targets.to(device)\n","        optimizer.zero_grad()\n","        preds = model(image)\n","        loss = loss_fn(preds, targets)\n","        loss.backward()\n","        optimizer.step()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","    print(f1_score(targets_list, preds_list, average=\"macro\"))\n"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 3140/3140 [08:23<00:00,  6.24it/s]\n"]}],"source":["test_dataset = ImageDataset(\"/data/ephemeral/home/data/sample_submission.csv\", \"/data/ephemeral/home/data/test\", transform=test_transform)\n","test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, pin_memory=True)\n","preds_list = []\n","model.eval()\n","with torch.no_grad():\n","    for image, _ in tqdm(test_loader):\n","        preds = model(image.to(device))\n","        preds_list.extend(preds.argmax(dim=1).cpu().numpy())\n","pd.DataFrame({'ID': test_dataset.df[:, 0], 'target': preds_list}).to_csv(\"sub.csv\", index=False)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
